{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVj2o9Y2AsYpus2evEftHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phucb2/lm-hackers/blob/main/Gpt_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPKFl0A-Bhna",
        "outputId": "8388b173-de16-438b-bcf7-e3246d598b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-01 16:13:38--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "\rinput.txt.1           0%[                    ]       0  --.-KB/s               \rinput.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-01-01 16:13:38 (162 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Go8ZY7zBjiJ",
        "outputId": "74c00e83-d6f1-4e15-b610-fd9639f82b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head input.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nf1k9XbBl8S",
        "outputId": "7ff973b6-fe1d-411e-a81c-a078fbfa815e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt') as file:\n",
        "  content = file.read()"
      ],
      "metadata": {
        "id": "op81Z06-BnGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3LMQ4XDBvUI",
        "outputId": "79a5e3f9-a45e-45a7-db54-47ace0507e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(set(list(content)))"
      ],
      "metadata": {
        "id": "eBVkgvqdBv-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyCLnn7GB8aN",
        "outputId": "54e5d6f2-fc9d-4b11-e384-9849c31aae65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''.join(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sksGw98rB9n_",
        "outputId": "c38c1b1d-a7c7-4800-bf8b-31657b53d35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {c:i for i, c in enumerate(chars)}\n",
        "itoc= {i:c for i, c in enumerate(chars)}\n",
        "\n",
        "encode = lambda s: [stoi[c] for c in s ]\n",
        "decode = lambda e: ''.join([itoc[i] for i in e])"
      ],
      "metadata": {
        "id": "7VBJ9qCoB-lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNVAjIiyC6jT",
        "outputId": "5c24c898-62a1-424c-d1cf-07a38bdc9380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[46, 43, 50, 50, 53]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode([46, 43, 50, 50, 53])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4BNa3CPOC8xf",
        "outputId": "9173cae4-7b10-4cca-c60d-e54b409549bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.tensor(encode(content), dtype=torch.long)\n",
        "tensor[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O--n0fNwC-nZ",
        "outputId": "e545bbbc-daed-4172-cc4c-06c51e726278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sz = int(len(tensor)*0.9)"
      ],
      "metadata": {
        "id": "Mlr0js4ZDYA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ts = tensor[:train_sz]\n",
        "valid_ts = tensor[train_sz:]"
      ],
      "metadata": {
        "id": "qAaasZFZDJxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_ts[:block_size+1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aboY2X1tDra3",
        "outputId": "3f6e656c-b106-4c2e-931d-d0f2de0fcf4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ts[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5jNlrfnE8T6",
        "outputId": "fda6555c-3c7f-4fe3-8a8c-262d7290341c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_ts[:block_size]\n",
        "y = train_ts[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when context {context} target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynU7OG-qEGM1",
        "outputId": "9d76be30-4b72-4671-fb30-5537a639c5f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when context tensor([18]) target is 47\n",
            "when context tensor([18, 47]) target is 56\n",
            "when context tensor([18, 47, 56]) target is 57\n",
            "when context tensor([18, 47, 56, 57]) target is 58\n",
            "when context tensor([18, 47, 56, 57, 58]) target is 1\n",
            "when context tensor([18, 47, 56, 57, 58,  1]) target is 15\n",
            "when context tensor([18, 47, 56, 57, 58,  1, 15]) target is 47\n",
            "when context tensor([18, 47, 56, 57, 58,  1, 15, 47]) target is 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(train_ts.shape[0] - block_size, (4,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx3eCUtiF7IM",
        "outputId": "5e46ee2e-b120-4921-f50e-d7b7b8b60dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([965347, 226082,  61742, 898828])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(203)\n",
        "batch_size = 4\n",
        "block_size = 8\n",
        "\n",
        "def get_batch(ds:str = 'train'):\n",
        "  data = train_ts if ds == 'train' else valid_ts\n",
        "  ix = torch.randint(data.shape[0] - block_size, (batch_size,))\n",
        "  xb = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  yb = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return xb, yb"
      ],
      "metadata": {
        "id": "Gl7kPVLSE2H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_batch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NTzhuxPGzJE",
        "outputId": "848a20d4-f1a1-4b07-cd36-c2e0f2cbaaee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0, 32, 46, 53, 59,  1, 61, 47],\n",
              "         [ 1, 58, 46, 43,  1, 51, 39, 58],\n",
              "         [58, 46,  1, 47, 52,  1, 44, 53],\n",
              "         [43, 57, 57, 43, 42,  1, 63, 53]]),\n",
              " tensor([[32, 46, 53, 59,  1, 61, 47, 50],\n",
              "         [58, 46, 43,  1, 51, 39, 58, 58],\n",
              "         [46,  1, 47, 52,  1, 44, 53, 56],\n",
              "         [57, 57, 43, 42,  1, 63, 53, 59]]))"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "nlGrQhFLIZ18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BigramLM(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.embd = nn.Embedding(vocab_size, vocab_size)\n",
        "  def forward(self, idx, targets=None):\n",
        "    logits = self.embd(idx) # (B, T, C) and C = vocab_size\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C) # (B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    return logits, loss\n",
        "  def generate(self,idx,max_generate):\n",
        "    for _ in range(max_generate):\n",
        "      logits, _ = self(idx) # B, T, C\n",
        "      logits = logits[:,-1,:]\n",
        "      probs = F.softmax(logits, dim=-1) # B, C\n",
        "      idx_next = torch.multinomial(probs, num_samples=1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1) # B, T+1\n",
        "    return idx\n",
        "\n",
        "\n",
        "bigramLM = BigramLM()\n",
        "sample = get_batch()\n",
        "o,l  = bigramLM(*sample)\n",
        "(o.shape, l.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXP8p7_SG0w1",
        "outputId": "f05e4386-9a16-4d52-fb1a-56243cb28460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 65]), torch.Size([]))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piuMnlmhIzGr",
        "outputId": "de5324e3-8253-47cf-9d63-86f8d11fd446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.6769, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = torch.zeros((1, 1), dtype=torch.long)\n",
        "g = bigramLM.generate(s, 100)"
      ],
      "metadata": {
        "id": "LzSyODghJyCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode(list(g[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tEmhmSAkL-2F",
        "outputId": "257d1fdb-bdbb-4858-f949-ff5f723a9fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nbJfZSM:vobzxEbnA&Hc!\\ne&aXxgZDRfYQHzI;-Sc!IPPVICsbQQe&PVHzdb&ct$bQsMp;.qVgHHwe$xQe  ZloaEcTbxETp,d&.T'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(m, max_size):\n",
        "  init = torch.zeros((1, 1), dtype=torch.long)\n",
        "  o = m.generate(init, max_size)\n",
        "  return decode(list(o[0].tolist()))"
      ],
      "metadata": {
        "id": "k7Ybfoj-OwNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epoches = 10000\n",
        "\n",
        "m = BigramLM()\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "for _ in range(epoches):\n",
        "  xb, yb = get_batch('train')\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  logits, loss = m(xb, yb)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4Yb087TNZOW",
        "outputId": "059e7d03-20f5-49fe-ae6a-20e6ae8360d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.497217893600464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(m, 500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGGG9xS4OZGt",
        "outputId": "22c3afa1-3634-43e6-fde6-230ed7407136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "She au g angero us y ais ft ive\n",
            "Uy aitllare bly?\n",
            "CUSird, ond&, bre y w, thes wory blereisuneesho t d, pest, ur!\n",
            "QUSathe m'diquthey ges,\n",
            "\n",
            "-at rd prik s.\n",
            "ghcyodio we, se st he jurslelikXmme army:\n",
            "Ar t idoupas t? ENG than,\n",
            "HUnowicice horoferexalan! be at Marbll?\n",
            "LORICI k. f ais ve ujanoure'thelithail th s Sofr nie inno w; s eckeryo t p s all3Jcanof wErre te ondanee lin l'che Qhe bers st woroupake tousswavengr lonse.\n",
            "Thoor in\n",
            "Highofasas, or vefawbe fas gere, ne f id kie He ir.\n",
            "\n",
            "Cos an OLABu RKIOMES:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2024)"
      ],
      "metadata": {
        "id": "_yPHLAlLPBJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0eec36-85e1-4e8a-c65c-cba7cc80acc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ec77272cd70>"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B, T, C = 4, 8, 2 # batch, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TUbqY5nziAX",
        "outputId": "ac4e84b7-bde8-4ec7-ea63-776b4ebce8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQg_EBd08xgc",
        "outputId": "c4b533b9-269d-40e2-89ac-ad7e1fb24760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2262, -0.0093],\n",
              "        [ 1.5420, -0.4657],\n",
              "        [ 0.2795, -0.2610],\n",
              "        [ 0.6230, -1.1561],\n",
              "        [ 0.1171, -1.8865],\n",
              "        [ 2.1822, -0.1930],\n",
              "        [ 0.5358, -0.8898],\n",
              "        [-0.3099,  0.7741]])"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B, T, C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev = x[b, :t+1] # (t, C)\n",
        "    xbow[b,t] = torch.mean(xprev, 0)"
      ],
      "metadata": {
        "id": "drfObylVztiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
        "xbow2 = wei @ x\n",
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv2q3mWs1sxO",
        "outputId": "7a946a63-d872-41c2-e467-ac29c8e117bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros(T, T)\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giZkK4G69oOc",
        "outputId": "950755f1-3e09-4f52-9001-3a8398472862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzc--us79H2k",
        "outputId": "549a3a27-e8a6-4a84-e37b-868d27b68fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNPL9qSq16aY",
        "outputId": "d206de3c-ec9b-4dd9-bf7e-29c43b75886a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9Orsc96z-QN",
        "outputId": "e820ab08-d922-4ff2-fd5a-c8bad7264a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tril(torch.ones(3, 3))\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceO-pNyg0heO",
        "outputId": "20628513-0e9a-435d-9cb1-63695f1db3f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a / torch.sum(a, 1, keepdim=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6swj7420ipw",
        "outputId": "42bc67fe-bea4-4813-ea24-a798daceec53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333]])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randint(0, 10, (3, 2)).float()"
      ],
      "metadata": {
        "id": "iNOSEQdH04KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWovMWup1XID",
        "outputId": "98bdfb55-b256-4400-ca04-256752f325f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8., 4.],\n",
              "        [7., 9.],\n",
              "        [3., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a @ b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk-zCX8_1ZLz",
        "outputId": "78e100c3-af19-4054-92b7-156d30d0ed0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8.,  4.],\n",
              "        [15., 13.],\n",
              "        [18., 21.]])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZnMl05Y9P8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obdDOUw_9P2T",
        "outputId": "18228a3c-5daa-4bfc-b6e3-cef7115eea61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3171, -1.8716],\n",
              "         [-0.0894,  0.7485],\n",
              "         [ 0.6137, -0.4419],\n",
              "         [ 0.0984, -0.1520],\n",
              "         [-0.5458,  0.9425],\n",
              "         [ 0.3299,  1.5264],\n",
              "         [-0.1864,  0.9193],\n",
              "         [-0.3248,  1.3998]],\n",
              "\n",
              "        [[-1.2415, -0.1413],\n",
              "         [-0.5798, -0.3694],\n",
              "         [-1.1544,  1.1677],\n",
              "         [ 0.1884,  1.3586],\n",
              "         [ 0.1845,  1.2366],\n",
              "         [ 0.9801,  0.1697],\n",
              "         [-0.9945,  1.1160],\n",
              "         [ 0.9171,  1.7905]],\n",
              "\n",
              "        [[ 0.7454, -0.2201],\n",
              "         [-0.1093,  0.7529],\n",
              "         [ 0.6874, -1.0833],\n",
              "         [-0.8231, -0.7953],\n",
              "         [ 0.9459, -0.9795],\n",
              "         [ 0.1056, -1.1015],\n",
              "         [-0.1636, -0.5730],\n",
              "         [ 0.6923, -0.3152]],\n",
              "\n",
              "        [[ 0.4694,  0.4213],\n",
              "         [ 1.3748,  0.2873],\n",
              "         [ 1.3502, -0.4173],\n",
              "         [-1.2381,  0.5010],\n",
              "         [-2.3167,  0.2943],\n",
              "         [ 0.9573,  0.2935],\n",
              "         [-1.6610, -1.7334],\n",
              "         [ 1.9739, -0.9289]]])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2024)\n",
        "B, T, C = 4, 8, 2\n",
        "# x = torch.randn(B, T, C)\n",
        "\n",
        "key = nn.Linear()\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros(T, T)\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iMKMABW1dAY",
        "outputId": "de80e445-e302-4561-8f6e-c09f166633a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEAvzboP9FTL",
        "outputId": "fa3f001f-a842-4bd7-b24c-d0369bec02e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHTNDlD57yWr",
        "outputId": "03d34cea-cb3f-4cbf-b587-df89869b7588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym6O4j_Y8BVg",
        "outputId": "528b27d6-67a5-44b3-9d42-73814fadf8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ_qIpTr8Qzg",
        "outputId": "495a88d1-47d2-49a5-ba09-efea81308ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.2914, -0.9938],\n",
              "        [ 0.7004, -0.5584],\n",
              "        [ 0.2362,  0.0455],\n",
              "        [ 0.0811, -0.1823],\n",
              "        [-0.1710, -0.3557],\n",
              "        [-0.3103, -0.3775],\n",
              "        [-0.2504, -0.4803],\n",
              "        [ 0.0190, -0.3806]])"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow3[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ3s_xw78Syl",
        "outputId": "3dd30419-cad5-4856-91ba-23755dab7fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3171, -1.8716],\n",
              "        [ 0.1138, -0.5615],\n",
              "        [ 0.2804, -0.5216],\n",
              "        [ 0.2349, -0.4292],\n",
              "        [ 0.0788, -0.1549],\n",
              "        [ 0.1206,  0.1253],\n",
              "        [ 0.0768,  0.2388],\n",
              "        [ 0.0266,  0.3839]])"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2024)\n",
        "B, T, C = 4, 8, 2\n",
        "# x = torch.randn(B, T, C)\n",
        "\n",
        "key = nn.Linear()\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros(T, T)\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "wei = wei / torch.sum(wei, 1, keepdim=True)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "id": "mP9GwDMP8UEc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}