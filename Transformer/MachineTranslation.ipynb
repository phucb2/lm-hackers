{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineTranslation.ipynb gpt-scatch.py            input.txt\n",
      "gpt-bqe.py               gpt.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = Path(\"../vn_numbers.txt\")\n",
    "# load first 1000 lines\n",
    "with file.open() as f:\n",
    "    lines = f.readlines()[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kho\\n', 'một \\n', 'hai \\n', 'ba \\n', 'bốn \\n']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove new line characters\n",
    "lines = [line.replace('\\n', '<eof>').strip() for line in lines]\n",
    "numbers = {str(index): s for index, s in enumerate(lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'một mươi bảy <eof>'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers['17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for num, text in numbers.items():\n",
    "    words = text.split() + [n for n in num]\n",
    "    # count words frequency and update vocab\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            vocab[word] += 1\n",
    "        else:\n",
    "            vocab[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_text = \"12 23\"\n",
    "# my_text.split('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort vocab by frequency\n",
    "vocab = {k: v for k, v in sorted(vocab.items(), key=lambda item: item[1], reverse=True)}\n",
    "vocab_list = list(vocab.keys())\n",
    "\n",
    "encode_text = lambda text: [vocab_list.index(word) for word in text.split()]\n",
    "decode_text = lambda encoded_text: ' '.join([vocab_list[index] for index in encoded_text])\n",
    "\n",
    "encode_int = lambda num: [vocab_list.index(n) for n in str(num)] + [vocab_list.index('<eof>')]\n",
    "decode_int = lambda encoded_num: int(''.join([vocab_list[index] for index in encoded_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 0]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"bốn bốn <eof>\"\n",
    "encoded_text = encode_text(sample_text)\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bốn bốn <eof>'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 7, 0]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_int = 123\n",
    "encoded_int = encode_int(sample_int)    \n",
    "encoded_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(value:any):\n",
    "    if isinstance(value, int):\n",
    "        return encode_int(value)\n",
    "    elif isinstance(value, str):\n",
    "        return encode_text(value)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid type\")\n",
    "\n",
    "def decode(encoded_value):\n",
    "    if isinstance(encoded_value[0], int):\n",
    "        return decode_int(encoded_value)\n",
    "    elif isinstance(encoded_value[0], str):\n",
    "        return decode_text(encoded_value)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "BLOCK_SIZE = 10\n",
    "\n",
    "# padding tensor same size\n",
    "def pad_tensor(t, size = BLOCK_SIZE):\n",
    "    t = torch.tensor(t)\n",
    "    pad_size = size - t.size(0)\n",
    "    return torch.cat([t, torch.zeros(pad_size).long()])\n",
    "\n",
    "def get_batch(data, batch_size=32):\n",
    "    random_pair_id = np.random.choice(len(data), batch_size)\n",
    "    xb = torch.stack([pad_tensor(encode(data[i])) for i in random_pair_id])\n",
    "    yb = torch.stack([pad_tensor(encode(int(i))) for i in random_pair_id])\n",
    "    return xb, yb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[17,  1, 19,  2,  4,  0,  0,  0,  0,  0],\n",
       "         [15,  1,  8,  2,  4,  0,  0,  0,  0,  0]]),\n",
       " tensor([[18, 10,  5,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [16,  9,  5,  0,  0,  0,  0,  0,  0,  0]]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch(lines,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(NaiveModel, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, 64)\n",
    "        self.fc = torch.nn.Linear(64, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.encoder_embedding = torch.nn.Embedding(vocab_size, 64)\n",
    "        self.decoder_embedding = torch.nn.Embedding(vocab_size, 64)\n",
    "        self.fc = torch.nn.Linear(64, vocab_size)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        x = self.encoder_embedding(x)\n",
    "        y = self.decoder_embedding(y)\n",
    "        # print(x.shape, y.shape)\n",
    "        l = self.fc(x + y)\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyModel(len(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10]) torch.Size([2, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 27])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = get_batch(lines, 2)\n",
    "print(xb.shape, yb.shape)\n",
    "logits = m(xb, yb)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_fnc(logits, targets):\n",
    "  B, T, C = logits.shape\n",
    "  logits = logits.view(B*T, C) # (B*T, C)\n",
    "  targets = targets.view(B*T)\n",
    "  loss = F.cross_entropy(logits, targets)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8916, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fnc(logits, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [1,2,3]\n",
    "s[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, prompt_idx, idx, max_tokens=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_tokens):\n",
    "            B, T = idx.shape\n",
    "            # fill the rest with zeros\n",
    "            filled_idx = torch.cat([idx, torch.zeros(B, BLOCK_SIZE - idx.size(1)).long()], dim=1)\n",
    "            x = model(prompt_idx, filled_idx)\n",
    "            logits = x[:,-1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat([idx, idx_next], dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.decode(encoded_value)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8,  1, 19,  2, 22,  0,  0,  0,  0,  0],\n",
       "        [20,  1, 11,  2,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = generate(m, xb, torch.zeros((2, 0), dtype=torch.long))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<eof> <eof> <eof> <eof> <eof> <eof> <eof> <eof> <eof> <eof>'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text(output[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs=10, batch_size=32, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        xb, yb = get_batch(data, batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb, yb)\n",
    "        loss = loss_fnc(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0027180525939911604\n",
      "Epoch 2, Loss: 0.0029453644528985023\n",
      "Epoch 3, Loss: 0.0028255023062229156\n",
      "Epoch 4, Loss: 0.0026756450533866882\n",
      "Epoch 5, Loss: 0.0021724016405642033\n",
      "Epoch 6, Loss: 0.002179615432396531\n",
      "Epoch 7, Loss: 0.0020899134688079357\n",
      "Epoch 8, Loss: 0.0018901836592704058\n",
      "Epoch 9, Loss: 0.0019376942655071616\n",
      "Epoch 10, Loss: 0.0016977936029434204\n",
      "Epoch 11, Loss: 0.0016265762969851494\n",
      "Epoch 12, Loss: 0.0017621457809582353\n",
      "Epoch 13, Loss: 0.0013842929620295763\n",
      "Epoch 14, Loss: 0.0013926068786531687\n",
      "Epoch 15, Loss: 0.0012404314475134015\n",
      "Epoch 16, Loss: 0.001330675557255745\n",
      "Epoch 17, Loss: 0.0010044557275250554\n",
      "Epoch 18, Loss: 0.0011635266710072756\n",
      "Epoch 19, Loss: 0.0011318838223814964\n",
      "Epoch 20, Loss: 0.0009333678754046559\n",
      "Epoch 21, Loss: 0.0009471686789765954\n",
      "Epoch 22, Loss: 0.000985773280262947\n",
      "Epoch 23, Loss: 0.0007857525488361716\n",
      "Epoch 24, Loss: 0.0009091047686524689\n",
      "Epoch 25, Loss: 0.0008945918525569141\n",
      "Epoch 26, Loss: 0.000887092319317162\n",
      "Epoch 27, Loss: 0.000822409987449646\n",
      "Epoch 28, Loss: 0.0006828272598795593\n",
      "Epoch 29, Loss: 0.0007116823107935488\n",
      "Epoch 30, Loss: 0.0007455120794475079\n",
      "Epoch 31, Loss: 0.0006857028929516673\n",
      "Epoch 32, Loss: 0.0006144344224594533\n",
      "Epoch 33, Loss: 0.000624464766588062\n",
      "Epoch 34, Loss: 0.000524968549143523\n",
      "Epoch 35, Loss: 0.00053276342805475\n",
      "Epoch 36, Loss: 0.0005036747315898538\n",
      "Epoch 37, Loss: 0.0006730635068379343\n",
      "Epoch 38, Loss: 0.0005193172837607563\n",
      "Epoch 39, Loss: 0.0005216681165620685\n",
      "Epoch 40, Loss: 0.0004899741034023464\n",
      "Epoch 41, Loss: 0.0005436322535388172\n",
      "Epoch 42, Loss: 0.0004364490450825542\n",
      "Epoch 43, Loss: 0.0003956800792366266\n",
      "Epoch 44, Loss: 0.00048085901653394103\n",
      "Epoch 45, Loss: 0.0004187587182968855\n",
      "Epoch 46, Loss: 0.00041751182288862765\n",
      "Epoch 47, Loss: 0.00039838231168687344\n",
      "Epoch 48, Loss: 0.00042565292096696794\n",
      "Epoch 49, Loss: 0.00044063720270060003\n",
      "Epoch 50, Loss: 0.0003320789255667478\n",
      "Epoch 51, Loss: 0.0003938621375709772\n",
      "Epoch 52, Loss: 0.00036008129245601594\n",
      "Epoch 53, Loss: 0.0003492351097520441\n",
      "Epoch 54, Loss: 0.0003652119485195726\n",
      "Epoch 55, Loss: 0.00034245854476466775\n",
      "Epoch 56, Loss: 0.00030103331664577127\n",
      "Epoch 57, Loss: 0.0003032243112102151\n",
      "Epoch 58, Loss: 0.00032625044696033\n",
      "Epoch 59, Loss: 0.00029771478148177266\n",
      "Epoch 60, Loss: 0.00029044138500466943\n",
      "Epoch 61, Loss: 0.00030496116960421205\n",
      "Epoch 62, Loss: 0.00028476055013015866\n",
      "Epoch 63, Loss: 0.00029341899789869785\n",
      "Epoch 64, Loss: 0.00028961003408767283\n",
      "Epoch 65, Loss: 0.0002377960627200082\n",
      "Epoch 66, Loss: 0.00027666843379847705\n",
      "Epoch 67, Loss: 0.00027370397583581507\n",
      "Epoch 68, Loss: 0.00024916103575378656\n",
      "Epoch 69, Loss: 0.0002814925683196634\n",
      "Epoch 70, Loss: 0.00025433380506001413\n",
      "Epoch 71, Loss: 0.00025510397972539067\n",
      "Epoch 72, Loss: 0.00021563249174505472\n",
      "Epoch 73, Loss: 0.00024130956444423646\n",
      "Epoch 74, Loss: 0.00023153619258664548\n",
      "Epoch 75, Loss: 0.00023466488346457481\n",
      "Epoch 76, Loss: 0.00023849210992921144\n",
      "Epoch 77, Loss: 0.00022160165826790035\n",
      "Epoch 78, Loss: 0.00021576038852799684\n",
      "Epoch 79, Loss: 0.00019088735280092806\n",
      "Epoch 80, Loss: 0.00021641298371832818\n",
      "Epoch 81, Loss: 0.0001987871219171211\n",
      "Epoch 82, Loss: 0.00022062165953684598\n",
      "Epoch 83, Loss: 0.00018091854872182012\n",
      "Epoch 84, Loss: 0.0001753798860590905\n",
      "Epoch 85, Loss: 0.0001834782597143203\n",
      "Epoch 86, Loss: 0.0001826808729674667\n",
      "Epoch 87, Loss: 0.00021573602862190455\n",
      "Epoch 88, Loss: 0.00019490985141601413\n",
      "Epoch 89, Loss: 0.00016209828027058393\n",
      "Epoch 90, Loss: 0.0001630590413697064\n",
      "Epoch 91, Loss: 0.0001801225880626589\n",
      "Epoch 92, Loss: 0.00017031957395374775\n",
      "Epoch 93, Loss: 0.00018723489483818412\n",
      "Epoch 94, Loss: 0.0001711855293251574\n",
      "Epoch 95, Loss: 0.00016089764540083706\n",
      "Epoch 96, Loss: 0.0001778945152182132\n",
      "Epoch 97, Loss: 0.00021835055667907\n",
      "Epoch 98, Loss: 0.0001543686812510714\n",
      "Epoch 99, Loss: 0.00016659146058373153\n",
      "Epoch 100, Loss: 0.0001590571628184989\n",
      "Epoch 101, Loss: 0.00016948986740317196\n",
      "Epoch 102, Loss: 0.00017227033094968647\n",
      "Epoch 103, Loss: 0.00017811385623645037\n",
      "Epoch 104, Loss: 0.0001605744328116998\n",
      "Epoch 105, Loss: 0.00014285527868196368\n",
      "Epoch 106, Loss: 0.0001649629120947793\n",
      "Epoch 107, Loss: 0.00013802453759126365\n",
      "Epoch 108, Loss: 0.0001466986577725038\n",
      "Epoch 109, Loss: 0.00014567111793439835\n",
      "Epoch 110, Loss: 0.00014773060684092343\n",
      "Epoch 111, Loss: 0.00014758137695025653\n",
      "Epoch 112, Loss: 0.00014765655214432627\n",
      "Epoch 113, Loss: 0.00012789361062459648\n",
      "Epoch 114, Loss: 9.90984117379412e-05\n",
      "Epoch 115, Loss: 0.00012092422548448667\n",
      "Epoch 116, Loss: 0.0001450383133487776\n",
      "Epoch 117, Loss: 0.00012906952179037035\n",
      "Epoch 118, Loss: 0.00013461285561788827\n",
      "Epoch 119, Loss: 0.00011666008504107594\n",
      "Epoch 120, Loss: 0.00012219413474667817\n",
      "Epoch 121, Loss: 0.00012673097080551088\n",
      "Epoch 122, Loss: 0.00012640940258279443\n",
      "Epoch 123, Loss: 0.00014028025907464325\n",
      "Epoch 124, Loss: 0.00013092799053993076\n",
      "Epoch 125, Loss: 0.00011985951277893037\n",
      "Epoch 126, Loss: 0.00012431769573595375\n",
      "Epoch 127, Loss: 0.00011576667748158798\n",
      "Epoch 128, Loss: 0.00012407380563672632\n",
      "Epoch 129, Loss: 0.00010827506048372015\n",
      "Epoch 130, Loss: 0.0001147404545918107\n",
      "Epoch 131, Loss: 0.00011818999337265268\n",
      "Epoch 132, Loss: 9.74140566540882e-05\n",
      "Epoch 133, Loss: 0.00011515894584590569\n",
      "Epoch 134, Loss: 0.00012681329098995775\n",
      "Epoch 135, Loss: 0.0001194961805595085\n",
      "Epoch 136, Loss: 0.00011571049981284887\n",
      "Epoch 137, Loss: 0.00012373662320896983\n",
      "Epoch 138, Loss: 0.00010390293027739972\n",
      "Epoch 139, Loss: 0.0001004607547656633\n",
      "Epoch 140, Loss: 0.00011097368405899033\n",
      "Epoch 141, Loss: 0.00010255568486172706\n",
      "Epoch 142, Loss: 0.00012411481293383986\n",
      "Epoch 143, Loss: 9.846683678915724e-05\n",
      "Epoch 144, Loss: 9.751311154104769e-05\n",
      "Epoch 145, Loss: 9.320716344518587e-05\n",
      "Epoch 146, Loss: 0.0001060550712281838\n",
      "Epoch 147, Loss: 8.791625441517681e-05\n",
      "Epoch 148, Loss: 9.389177284901962e-05\n",
      "Epoch 149, Loss: 9.057363786268979e-05\n",
      "Epoch 150, Loss: 9.846770990407094e-05\n",
      "Epoch 151, Loss: 0.00011932213965337723\n",
      "Epoch 152, Loss: 9.995349682867527e-05\n",
      "Epoch 153, Loss: 8.792699372861534e-05\n",
      "Epoch 154, Loss: 9.991224214900285e-05\n",
      "Epoch 155, Loss: 9.794678771868348e-05\n",
      "Epoch 156, Loss: 8.362887456314638e-05\n",
      "Epoch 157, Loss: 8.115990931401029e-05\n",
      "Epoch 158, Loss: 8.726546366233379e-05\n",
      "Epoch 159, Loss: 9.122850315179676e-05\n",
      "Epoch 160, Loss: 9.754355414770544e-05\n",
      "Epoch 161, Loss: 8.772822184255347e-05\n",
      "Epoch 162, Loss: 7.978890062076971e-05\n",
      "Epoch 163, Loss: 6.679860962321982e-05\n",
      "Epoch 164, Loss: 7.275347161339596e-05\n",
      "Epoch 165, Loss: 8.028752927202731e-05\n",
      "Epoch 166, Loss: 7.950713916216046e-05\n",
      "Epoch 167, Loss: 8.804794197203591e-05\n",
      "Epoch 168, Loss: 7.799874583724886e-05\n",
      "Epoch 169, Loss: 7.659772381884977e-05\n",
      "Epoch 170, Loss: 8.53456076583825e-05\n",
      "Epoch 171, Loss: 7.637511589564383e-05\n",
      "Epoch 172, Loss: 8.790010906523094e-05\n",
      "Epoch 173, Loss: 6.936168938409537e-05\n",
      "Epoch 174, Loss: 7.240662671392784e-05\n",
      "Epoch 175, Loss: 7.976510823937133e-05\n",
      "Epoch 176, Loss: 6.862072041258216e-05\n",
      "Epoch 177, Loss: 6.526946526719257e-05\n",
      "Epoch 178, Loss: 7.16391223249957e-05\n",
      "Epoch 179, Loss: 7.96050371718593e-05\n",
      "Epoch 180, Loss: 7.48887105146423e-05\n",
      "Epoch 181, Loss: 7.040407945169136e-05\n",
      "Epoch 182, Loss: 7.546480628661811e-05\n",
      "Epoch 183, Loss: 7.318275311263278e-05\n",
      "Epoch 184, Loss: 6.92746980348602e-05\n",
      "Epoch 185, Loss: 6.617215694859624e-05\n",
      "Epoch 186, Loss: 6.794837099732831e-05\n",
      "Epoch 187, Loss: 6.668219430139288e-05\n",
      "Epoch 188, Loss: 7.685671153012663e-05\n",
      "Epoch 189, Loss: 6.01438878220506e-05\n",
      "Epoch 190, Loss: 6.414085510186851e-05\n",
      "Epoch 191, Loss: 7.163274858612567e-05\n",
      "Epoch 192, Loss: 6.726385618094355e-05\n",
      "Epoch 193, Loss: 7.349038787651807e-05\n",
      "Epoch 194, Loss: 6.704802217427641e-05\n",
      "Epoch 195, Loss: 6.823057628935203e-05\n",
      "Epoch 196, Loss: 7.479260966647416e-05\n",
      "Epoch 197, Loss: 6.331482290988788e-05\n",
      "Epoch 198, Loss: 7.652005297131836e-05\n",
      "Epoch 199, Loss: 7.568973524030298e-05\n",
      "Epoch 200, Loss: 6.48345667286776e-05\n"
     ]
    }
   ],
   "source": [
    "train(m, lines, epochs=200, batch_size=32, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
